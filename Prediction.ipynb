{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#data preprocessing\n",
    "import pandas as pd\n",
    "#produces a prediction model in the form of an ensemble of weak prediction models, typically decision tree\n",
    "#the outcome (dependent variable) has only a limited number of possible values. \n",
    "#Logistic Regression is used when response variable is categorical in nature.\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "#A random forest is a meta estimator that fits a number of decision tree classifiers \n",
    "#on various sub-samples of the dataset and use averaging to improve the predictive \n",
    "#accuracy and control over-fitting.\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "#-----------------------------------------------------------------------------------------------------------\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "#-------------------------------------------------------------------------------------------------------------\n",
    "from sklearn.svm import SVC\n",
    "#displayd data\n",
    "from IPython.display import display\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>FTR</th>\n",
       "      <th>HTP</th>\n",
       "      <th>ATP</th>\n",
       "      <th>HM1</th>\n",
       "      <th>HM2</th>\n",
       "      <th>HM3</th>\n",
       "      <th>AM1</th>\n",
       "      <th>AM2</th>\n",
       "      <th>AM3</th>\n",
       "      <th>HTGD</th>\n",
       "      <th>ATGD</th>\n",
       "      <th>DiffFormPts</th>\n",
       "      <th>DiffLP</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>6075</th>\n",
       "      <td>H</td>\n",
       "      <td>1.263158</td>\n",
       "      <td>1.631579</td>\n",
       "      <td>L</td>\n",
       "      <td>D</td>\n",
       "      <td>L</td>\n",
       "      <td>W</td>\n",
       "      <td>L</td>\n",
       "      <td>W</td>\n",
       "      <td>-0.394737</td>\n",
       "      <td>0.394737</td>\n",
       "      <td>-0.236842</td>\n",
       "      <td>-3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6076</th>\n",
       "      <td>NH</td>\n",
       "      <td>1.210526</td>\n",
       "      <td>1.710526</td>\n",
       "      <td>W</td>\n",
       "      <td>W</td>\n",
       "      <td>L</td>\n",
       "      <td>D</td>\n",
       "      <td>L</td>\n",
       "      <td>W</td>\n",
       "      <td>-0.263158</td>\n",
       "      <td>0.789474</td>\n",
       "      <td>0.026316</td>\n",
       "      <td>6.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6077</th>\n",
       "      <td>NH</td>\n",
       "      <td>1.157895</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>L</td>\n",
       "      <td>L</td>\n",
       "      <td>W</td>\n",
       "      <td>W</td>\n",
       "      <td>W</td>\n",
       "      <td>D</td>\n",
       "      <td>-0.263158</td>\n",
       "      <td>-0.368421</td>\n",
       "      <td>-0.131579</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6078</th>\n",
       "      <td>NH</td>\n",
       "      <td>1.105263</td>\n",
       "      <td>1.552632</td>\n",
       "      <td>D</td>\n",
       "      <td>L</td>\n",
       "      <td>D</td>\n",
       "      <td>D</td>\n",
       "      <td>W</td>\n",
       "      <td>L</td>\n",
       "      <td>-0.368421</td>\n",
       "      <td>0.342105</td>\n",
       "      <td>-0.157895</td>\n",
       "      <td>7.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6079</th>\n",
       "      <td>H</td>\n",
       "      <td>1.657895</td>\n",
       "      <td>1.105263</td>\n",
       "      <td>L</td>\n",
       "      <td>W</td>\n",
       "      <td>D</td>\n",
       "      <td>D</td>\n",
       "      <td>L</td>\n",
       "      <td>L</td>\n",
       "      <td>0.315789</td>\n",
       "      <td>-0.526316</td>\n",
       "      <td>0.157895</td>\n",
       "      <td>-14.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     FTR       HTP       ATP HM1 HM2 HM3 AM1 AM2 AM3      HTGD      ATGD  \\\n",
       "6075   H  1.263158  1.631579   L   D   L   W   L   W -0.394737  0.394737   \n",
       "6076  NH  1.210526  1.710526   W   W   L   D   L   W -0.263158  0.789474   \n",
       "6077  NH  1.157895  1.000000   L   L   W   W   W   D -0.263158 -0.368421   \n",
       "6078  NH  1.105263  1.552632   D   L   D   D   W   L -0.368421  0.342105   \n",
       "6079   H  1.657895  1.105263   L   W   D   D   L   L  0.315789 -0.526316   \n",
       "\n",
       "      DiffFormPts  DiffLP  \n",
       "6075    -0.236842    -3.0  \n",
       "6076     0.026316     6.0  \n",
       "6077    -0.131579     2.0  \n",
       "6078    -0.157895     7.0  \n",
       "6079     0.157895   -14.0  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Read data and drop redundant column.\n",
    "data = pd.read_csv('final_dataset_1.csv', index_col = 0)\n",
    "#data.drop(columns=[''])\n",
    "# Preview data.\n",
    "display(data.tail())\n",
    "\n",
    "\n",
    "#Full Time Result (H=Home Win, D=Draw, A=Away Win)\n",
    "#HTGD - Home team goal difference\n",
    "#ATGD - away team goal difference\n",
    "#HTP - Home team points\n",
    "#ATP - Away team points\n",
    "#DiffFormPts Diff in points\n",
    "#DiffLP - Differnece in last years prediction\n",
    "\n",
    "#Input - 12 other features (fouls, shots, goals, misses,corners, red card, yellow cards)\n",
    "#Output - Full Time Result (H=Home Win, D=Draw, A=Away Win)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of matches:6080\n",
      "Number of features: 12\n",
      "Number of matches won by home team: 2816\n",
      "Win rate of home team: 46.31578947368421%\n"
     ]
    }
   ],
   "source": [
    "#what is the win rate for the home team?\n",
    "\n",
    "# Total number of matches.\n",
    "n_matches = data.shape[0]\n",
    "\n",
    "# Calculate number of features. -1 because we are saving one as the target variable (win/lose/draw)\n",
    "n_features = data.shape[1] - 1\n",
    "\n",
    "# Calculate matches won by home team.\n",
    "n_homewins = len(data[data.FTR == 'H'])\n",
    "\n",
    "# Calculate win rate for home team.\n",
    "win_rate = (float(n_homewins) / (n_matches)) * 100\n",
    "\n",
    "# Print the results\n",
    "print (\"Total number of matches:\"+ str(n_matches))\n",
    "print (\"Number of features: \"+str(n_features))\n",
    "print (\"Number of matches won by home team: \"+str(n_homewins))\n",
    "print (\"Win rate of home team: \"+ str(win_rate) + \"%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Separate into feature set and target variable\n",
    "#FTR = Full Time Result (H=Home Win, D=Draw, A=Away Win)\n",
    "X_all = data.drop(['FTR'],1)\n",
    "y_all = data['FTR']\n",
    "\n",
    "# Standardising the data.\n",
    "from sklearn.preprocessing import scale\n",
    "\n",
    "#Center to the mean and component wise scale to unit variance.\n",
    "cols = [['HTGD','ATGD','HTP','ATP','DiffLP']]\n",
    "for col in cols:\n",
    "    X_all[col] = scale(X_all[col])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed feature columns (30 total features):\n",
      "['HTP', 'ATP', 'HM1_D', 'HM1_L', 'HM1_M', 'HM1_W', 'HM2_D', 'HM2_L', 'HM2_M', 'HM2_W', 'HM3_D', 'HM3_L', 'HM3_M', 'HM3_W', 'AM1_D', 'AM1_L', 'AM1_M', 'AM1_W', 'AM2_D', 'AM2_L', 'AM2_M', 'AM2_W', 'AM3_D', 'AM3_L', 'AM3_M', 'AM3_W', 'HTGD', 'ATGD', 'DiffFormPts', 'DiffLP']\n"
     ]
    }
   ],
   "source": [
    "#last 3 wins for both sides\n",
    "X_all.HM1 = X_all.HM1.astype('str')\n",
    "X_all.HM2 = X_all.HM2.astype('str')\n",
    "X_all.HM3 = X_all.HM3.astype('str')\n",
    "X_all.AM1 = X_all.AM1.astype('str')\n",
    "X_all.AM2 = X_all.AM2.astype('str')\n",
    "X_all.AM3 = X_all.AM3.astype('str')\n",
    "\n",
    "#we want continous vars that are integers for our input data, so lets remove any categorical vars\n",
    "def preprocess_features(X):\n",
    "    ''' Preprocesses the football data and converts catagorical variables into dummy variables. '''\n",
    "    \n",
    "    # Initialize new output DataFrame\n",
    "    output = pd.DataFrame(index = X.index)\n",
    "\n",
    "    # Investigate each feature column for the data\n",
    "    for col, col_data in X.iteritems():\n",
    "\n",
    "        # If data type is categorical, convert to dummy variables\n",
    "        if col_data.dtype == object:\n",
    "            col_data = pd.get_dummies(col_data, prefix = col)\n",
    "                    \n",
    "        # Collect the revised columns\n",
    "        output = output.join(col_data)\n",
    "    \n",
    "    return output\n",
    "\n",
    "X_all = preprocess_features(X_all)\n",
    "print (\"Processed feature columns (\"+str(len(X_all.columns))+\" total features):\\n\"+str(list(X_all.columns)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Feature values:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>HTP</th>\n",
       "      <th>ATP</th>\n",
       "      <th>HM1_D</th>\n",
       "      <th>HM1_L</th>\n",
       "      <th>HM1_M</th>\n",
       "      <th>HM1_W</th>\n",
       "      <th>HM2_D</th>\n",
       "      <th>HM2_L</th>\n",
       "      <th>HM2_M</th>\n",
       "      <th>HM2_W</th>\n",
       "      <th>...</th>\n",
       "      <th>AM2_M</th>\n",
       "      <th>AM2_W</th>\n",
       "      <th>AM3_D</th>\n",
       "      <th>AM3_L</th>\n",
       "      <th>AM3_M</th>\n",
       "      <th>AM3_W</th>\n",
       "      <th>HTGD</th>\n",
       "      <th>ATGD</th>\n",
       "      <th>DiffFormPts</th>\n",
       "      <th>DiffLP</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-2.303259</td>\n",
       "      <td>-2.373125</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.014963</td>\n",
       "      <td>-0.022914</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-2.303259</td>\n",
       "      <td>-2.373125</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.014963</td>\n",
       "      <td>-0.022914</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.496101</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-2.303259</td>\n",
       "      <td>-2.373125</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.014963</td>\n",
       "      <td>-0.022914</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.248051</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-2.303259</td>\n",
       "      <td>-2.373125</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.014963</td>\n",
       "      <td>-0.022914</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.124025</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-2.303259</td>\n",
       "      <td>-2.373125</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.014963</td>\n",
       "      <td>-0.022914</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-1.240253</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 30 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        HTP       ATP  HM1_D  HM1_L  HM1_M  HM1_W  HM2_D  HM2_L  HM2_M  HM2_W  \\\n",
       "0 -2.303259 -2.373125      0      0      1      0      0      0      1      0   \n",
       "1 -2.303259 -2.373125      0      0      1      0      0      0      1      0   \n",
       "2 -2.303259 -2.373125      0      0      1      0      0      0      1      0   \n",
       "3 -2.303259 -2.373125      0      0      1      0      0      0      1      0   \n",
       "4 -2.303259 -2.373125      0      0      1      0      0      0      1      0   \n",
       "\n",
       "   ...  AM2_M  AM2_W  AM3_D  AM3_L  AM3_M  AM3_W      HTGD      ATGD  \\\n",
       "0  ...      1      0      0      0      1      0  0.014963 -0.022914   \n",
       "1  ...      1      0      0      0      1      0  0.014963 -0.022914   \n",
       "2  ...      1      0      0      0      1      0  0.014963 -0.022914   \n",
       "3  ...      1      0      0      0      1      0  0.014963 -0.022914   \n",
       "4  ...      1      0      0      0      1      0  0.014963 -0.022914   \n",
       "\n",
       "   DiffFormPts    DiffLP  \n",
       "0          0.0  0.000000  \n",
       "1          0.0 -0.496101  \n",
       "2          0.0  0.248051  \n",
       "3          0.0  0.124025  \n",
       "4          0.0 -1.240253  \n",
       "\n",
       "[5 rows x 30 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Show the feature information by printing the first five rows\n",
    "print (\"\\nFeature values:\")\n",
    "display(X_all.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Shuffle and split the dataset into training and testing set.\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_all, y_all, \n",
    "                                                    test_size = 50,\n",
    "                                                    random_state = 2,\n",
    "                                                    stratify = y_all)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#for measuring training time\n",
    "from time import time \n",
    "# F1 score (also F-score or F-measure) is a measure of a test's accuracy. \n",
    "#It considers both the precision p and the recall r of the test to compute \n",
    "#the score: p is the number of correct positive results divided by the number of \n",
    "#all positive results, and r is the number of correct positive results divided by \n",
    "#the number of positive results that should have been returned. The F1 score can be \n",
    "#interpreted as a weighted average of the precision and recall, where an F1 score \n",
    "#reaches its best value at 1 and worst at 0.\n",
    "from sklearn.metrics import f1_score\n",
    "\n",
    "def train_classifier(clf, X_train, y_train):\n",
    "    ''' Fits a classifier to the training data. '''\n",
    "    \n",
    "    # Start the clock, train the classifier, then stop the clock\n",
    "    start = time()\n",
    "    clf.fit(X_train, y_train)\n",
    "    end = time()\n",
    "    \n",
    "    # Print the results\n",
    "    print (\"Trained model in {:.4f} seconds\".format(end - start))\n",
    "\n",
    "    \n",
    "def predict_labels(clf, features, target):\n",
    "    ''' Makes predictions using a fit classifier based on F1 score. '''\n",
    "    \n",
    "    # Start the clock, make predictions, then stop the clock\n",
    "    start = time()\n",
    "    y_pred = clf.predict(features)\n",
    "    \n",
    "    end = time()\n",
    "    # Print and return results\n",
    "    print (\"Made predictions in {:.4f} seconds.\".format(end - start))\n",
    "    \n",
    "    return f1_score(target, y_pred, pos_label='H'), sum(target == y_pred) / float(len(y_pred))\n",
    "\n",
    "\n",
    "def train_predict(clf, X_train, y_train, X_test, y_test):\n",
    "    ''' Train and predict using a classifer based on F1 score. '''\n",
    "    \n",
    "    # Indicate the classifier and the training set size\n",
    "    print (\"Training a {} using a training set size of {}. . .\".format(clf.__class__.__name__, len(X_train)))\n",
    "    \n",
    "    # Train the classifier\n",
    "    train_classifier(clf, X_train, y_train)\n",
    "    \n",
    "    # Print the results of prediction for both training and testing\n",
    "    f1, acc = predict_labels(clf, X_train, y_train)\n",
    "    print (f1, acc)\n",
    "    print (\"F1 score and accuracy score for training set: {:.4f} , {:.4f}.\".format(f1 , acc))\n",
    "    \n",
    "    f1, acc = predict_labels(clf, X_test, y_test)\n",
    "    print (\"F1 score and accuracy score for test set: {:.4f} , {:.4f}.\".format(f1 , acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gaussian Naive Bayes model accuracy(in %): 70.0\n",
      "Training a LogisticRegression using a training set size of 6030. . .\n",
      "Trained model in 0.0309 seconds\n",
      "Made predictions in 0.0020 seconds.\n",
      "0.6142533936651584 0.6606965174129353\n",
      "F1 score and accuracy score for training set: 0.6143 , 0.6607.\n",
      "Made predictions in 0.0010 seconds.\n",
      "F1 score and accuracy score for test set: 0.6818 , 0.7200.\n",
      "\n",
      "Training a SVC using a training set size of 6030. . .\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\admin\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\admin\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\base.py:196: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trained model in 2.2999 seconds\n",
      "Made predictions in 1.3105 seconds.\n",
      "0.6134387351778657 0.6756218905472637\n",
      "F1 score and accuracy score for training set: 0.6134 , 0.6756.\n",
      "Made predictions in 0.0110 seconds.\n",
      "F1 score and accuracy score for test set: 0.6818 , 0.7200.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Initialize the three models (XGBoost is initialized later)\n",
    "clf_A = LogisticRegression(random_state = 42)\n",
    "clf_B = SVC(random_state = 912, kernel='rbf')\n",
    "#----------------------------------------------------------------------------------------------------\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "gnb = GaussianNB() \n",
    "gnb.fit(X_train, y_train) \n",
    "y_pred = gnb.predict(X_test) \n",
    "from sklearn import metrics \n",
    "#----------------------------------------------------------------------------------------------------\n",
    "\n",
    "train_predict(clf_A, X_train, y_train, X_test, y_test)\n",
    "print ('')\n",
    "train_predict(clf_B, X_train, y_train, X_test, y_test)\n",
    "print ('')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gaussian Naive Bayes model accuracy(in %): 70.0\n"
     ]
    }
   ],
   "source": [
    "print(\"Gaussian Naive Bayes model accuracy(in %):\", metrics.accuracy_score(y_test, y_pred)*100)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
